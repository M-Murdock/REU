{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn import preprocessing\n",
    "from pandas import DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "#grab random 200,000 entries from the original file, put them in a new csv called 'data.csv'\n",
    "\n",
    "import random\n",
    "FILE='read_data/read_data_1.csv'\n",
    "data = pd.read_csv(FILE)\n",
    "\n",
    "n =  len(data)\n",
    "s = 200000 \n",
    "skip = sorted(random.sample(range(1,n+1),n-s)) \n",
    "data = pd.read_csv(FILE, skiprows=skip)\n",
    "data.to_csv(\"working_data/data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 200000 entries, 0 to 199999\n",
      "Data columns (total 15 columns):\n",
      " #   Column     Non-Null Count   Dtype  \n",
      "---  ------     --------------   -----  \n",
      " 0   StartTime  200000 non-null  object \n",
      " 1   Dur        200000 non-null  float64\n",
      " 2   Proto      200000 non-null  object \n",
      " 3   SrcAddr    200000 non-null  object \n",
      " 4   Sport      199356 non-null  object \n",
      " 5   Dir        200000 non-null  object \n",
      " 6   DstAddr    200000 non-null  object \n",
      " 7   Dport      199678 non-null  object \n",
      " 8   State      200000 non-null  object \n",
      " 9   sTos       199272 non-null  float64\n",
      " 10  dTos       185980 non-null  float64\n",
      " 11  TotPkts    200000 non-null  int64  \n",
      " 12  TotBytes   200000 non-null  int64  \n",
      " 13  SrcBytes   200000 non-null  int64  \n",
      " 14  Label      200000 non-null  object \n",
      "dtypes: float64(3), int64(3), object(9)\n",
      "memory usage: 22.9+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(data.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Drop missing entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop any rows with missing data\n",
    "\n",
    "data.dropna(inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert all the data to numerical values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set Dummy Values\n",
    "\n",
    "labelEncoder = preprocessing.LabelEncoder()\n",
    "labelEncoder.fit(data['Proto'])\n",
    "data['Proto'] = labelEncoder.transform(data['Proto'])\n",
    "\n",
    "labelEncoder.fit(data['State'])\n",
    "data['State'] = labelEncoder.transform(data['State'])\n",
    "\n",
    "labelEncoder.fit(data['Dir'])\n",
    "data['Dir'] = labelEncoder.transform(data['Dir'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert StartTime to epoch\n",
    "\n",
    "start_time = data['StartTime'].tolist()\n",
    "\n",
    "for index in range(0, len(start_time)):\n",
    "    start_time[index] = pd.to_datetime(start_time[index]).timestamp() \n",
    "    \n",
    "data['StartTime'] = start_time \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert dst/src addresses to numerical values (delete the row if the value cannot be converted)\n",
    "\n",
    "src_addr = data['SrcAddr'].tolist()\n",
    "dst_addr = data['DstAddr'].tolist()\n",
    "\n",
    "for index in range(0, len(src_addr)):\n",
    "    try:\n",
    "        src_addr[index] = int(str(src_addr[index]).replace('.', ''))\n",
    "    except: \n",
    "        data = data.drop(data.index[index])\n",
    "    \n",
    "for index in range(0, len(dst_addr)):\n",
    "    try: \n",
    "        dst_addr[index] = int(str(dst_addr[index]).replace('.', ''))\n",
    "    except: \n",
    "        data = data.drop(data.index[index])\n",
    "    \n",
    "data[\"SrcAddr\"] = src_addr\n",
    "data[\"DstAddr\"] = dst_addr\n",
    "data.to_csv(\"working_data/data.csv\", index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert Sport and Dport to numerical values\n",
    "\n",
    "rows = list(data['Sport'])\n",
    "for row_index in range(0, len(rows)):\n",
    "    try:\n",
    "        rows[row_index] = row[row_index].astype(np.float32)\n",
    "    except:\n",
    "        rows[row_index] = 0\n",
    "data['Sport'] = rows\n",
    "\n",
    "\n",
    "rows = list(data['Dport'])\n",
    "for row_index in range(0, len(rows)):\n",
    "    try:\n",
    "        rows[row_index] = rows[row_index].astype(np.float32)\n",
    "    except:\n",
    "        rows[row_index] = 0\n",
    "data['Dport'] = rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert Label column to numerical values. 1 if botnet, 0 if benign. \n",
    "# Store the botnet and benign flows in separate csv files.\n",
    "\n",
    "\n",
    "# create a list of all the labels\n",
    "label_entries = list(data['Label'])\n",
    "\n",
    "#create lists for storing botnet and benign flows\n",
    "botnets = list()\n",
    "benign = list()\n",
    "\n",
    "#convert botnet entries to 1, benign to 0\n",
    "index = 0\n",
    "for entry in data['Label']:\n",
    "    # non-TCP and UDP protocols are outliers too, so remove them\n",
    "    if not 'TCP' in entry and not 'UDP' in entry:\n",
    "        label_entries[index] = -1\n",
    "    else:\n",
    "        if 'botnet' in entry or 'Botnet' in entry:\n",
    "            label_entries[index] = 1\n",
    "\n",
    "        else:\n",
    "            if not entry == 1 and not entry == 0:\n",
    "                label_entries[index] = 0\n",
    "    index += 1\n",
    "        \n",
    "# data['Label'] = label_entries\n",
    "# data.to_csv(\"working_data/data.csv\", index=False)\n",
    "\n",
    "\n",
    "# Store the benign and botnet data in separate arrays\n",
    "# Convert benign and botnet to dataframes, save in csv files\n",
    "\n",
    "index = 0\n",
    "for entry in label_entries:\n",
    "    if entry == 1:\n",
    "        botnets.append(list(data.iloc[index]))\n",
    "    elif entry == 0:\n",
    "        benign.append(list(data.iloc[index]))\n",
    "    index += 1\n",
    "\n",
    "benign = DataFrame (benign,columns=list(data.columns))\n",
    "botnets = DataFrame (botnets,columns=list(data.columns))\n",
    "\n",
    "botnets.to_csv(\"working_data/botnet.csv\", index=False)\n",
    "benign.to_csv(\"working_data/benign.csv\", index=False)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove outliers\n",
    "\n",
    "from numpy.random import seed\n",
    "from numpy.random import randn\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "\n",
    "\n",
    "no_outliers = list()\n",
    "outliers = list()\n",
    "\n",
    "#loop through each relevant column to find the outliers\n",
    "for name in ['Dur', 'TotBytes', 'SrcBytes', 'TotPkts']:\n",
    "    \n",
    "    col = benign[name]\n",
    "    \n",
    "    # calculate summary statistics\n",
    "    data_mean, data_std = mean(col), std(col)\n",
    "    \n",
    "    # identify outliers\n",
    "    cut_off = data_std * 3\n",
    "    lower, upper = data_mean - cut_off, data_mean + cut_off\n",
    "\n",
    "    # find locations of the outliers\n",
    "    index = 0\n",
    "    for x in col:\n",
    "        #check for protocol outliers\n",
    "        if name == 'Label':\n",
    "            if x == -1:\n",
    "                outliers.append(index)\n",
    "                \n",
    "        if x < lower or x > upper:\n",
    "            outliers.append(index)\n",
    "        index += 1\n",
    "    \n",
    "#remove duplicates\n",
    "outliers = list(dict.fromkeys(outliers))   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine the reduced list of benign flows with the botnet flows\n",
    "# Convert the list to csv\n",
    "\n",
    "no_outliers = DataFrame (pd.concat([benign.drop(benign.index[outliers]), botnets], ignore_index=True))\n",
    "\n",
    "no_outliers.to_csv(\"working_data/no_outliers.csv\", index=False)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
