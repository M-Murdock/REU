{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn import preprocessing\n",
    "from pandas import DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Store Botnet/Benign flows in separate csv files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in data\n",
    "data = pd.read_csv('working_data/data.csv')\n",
    "\n",
    "# create a list of all the labels\n",
    "label_entries = list(data['Label'])\n",
    "\n",
    "#create lists for storing botnet and benign flows\n",
    "botnets = list()\n",
    "benign = list()\n",
    "\n",
    "\n",
    "# Store the benign and botnet data in separate arrays\n",
    "\n",
    "index = 0\n",
    "for entry in data['Label']:\n",
    "    if not 'TCP' in entry and not 'UDP' in entry:\n",
    "        label_entries[index] = -1\n",
    "    else:\n",
    "        if 'botnet' in entry or 'Botnet' in entry:\n",
    "            botnets.append(list(data.iloc[index]))\n",
    "        else:\n",
    "            benign.append(list(data.iloc[index]))\n",
    "    index += 1\n",
    "\n",
    "    \n",
    "# Convert benign and botnet to dataframes, save in csv files\n",
    "\n",
    "benign = DataFrame (benign,columns=list(data.columns))\n",
    "botnets = DataFrame (botnets,columns=list(data.columns))\n",
    "\n",
    "botnets.to_csv(\"botnet.csv\", index=False)\n",
    "benign.to_csv(\"benign.csv\", index=False)\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using lists of benign/botnets in string format, remove the outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove outliers\n",
    "\n",
    "from numpy.random import seed\n",
    "from numpy.random import randn\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "\n",
    "\n",
    "no_outliers = list()\n",
    "outliers = list()\n",
    "\n",
    "#loop through each relevant column to find the outliers\n",
    "for name in ['Dur', 'TotBytes', 'SrcBytes', 'TotPkts']:\n",
    "    \n",
    "    col = benign[name]\n",
    "    \n",
    "    # calculate summary statistics\n",
    "    data_mean, data_std = mean(col), std(col)\n",
    "    \n",
    "    # identify outliers\n",
    "    cut_off = data_std * 3\n",
    "    lower, upper = data_mean - cut_off, data_mean + cut_off\n",
    "\n",
    "    # find locations of the outliers\n",
    "    index = 0\n",
    "    for x in col:\n",
    "        #check for protocol outliers\n",
    "        if name == 'Label':\n",
    "            if x == -1:\n",
    "                outliers.append(index)\n",
    "                \n",
    "        if x < lower or x > upper:\n",
    "            outliers.append(index)\n",
    "        index += 1\n",
    "    \n",
    "#remove duplicates\n",
    "outliers = list(dict.fromkeys(outliers))   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine the reduced list of benign flows with the botnet flows\n",
    "# Convert the list to csv\n",
    "\n",
    "no_outliers = DataFrame (pd.concat([benign.drop(benign.index[outliers]), botnets], ignore_index=True))\n",
    "\n",
    "no_outliers.to_csv(\"no_outliers.csv\", index=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read from no_outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_outliers = pd.read_csv('working_data/no_outliers.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-Means Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "#get all the features except StartTime and Label\n",
    "x = no_outliers.iloc[:,1:14]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#counts the number of botnets and benign flows in each cluster, given a list of the labels and the # clusters\n",
    "def count_groups(n, labels, centroids):\n",
    "    # Make a list of dictionaries for storing counts of botnet and benign flows for each cluster\n",
    "    counts = list()\n",
    "    \n",
    "    for index in range(0, n):\n",
    "#         counts.append( {'label': 0, 'centroid': list()} )\n",
    "        counts.append({})\n",
    "\n",
    "    #Iterate through each individual cluster\n",
    "    for index in range(0, len(labels)):\n",
    "        \n",
    "        try:\n",
    "            counts[labels[index]][no_outliers['Label'][index]] += 1\n",
    "        except:\n",
    "            counts[labels[index]][no_outliers['Label'][index]] = 0\n",
    "            \n",
    "            \n",
    "#         counts[labels[index]]['label'] = labels[index]\n",
    "#         counts[labels[index]]['centroid'] = centroids[labels[index]]\n",
    "            \n",
    "    return counts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "success!\n"
     ]
    }
   ],
   "source": [
    "# For each cluster, print out the number of types of each botnet and benign \n",
    "import xlwt\n",
    "from xlwt import Workbook\n",
    "\n",
    "\n",
    "kmeans = KMeans(n_clusters=30)\n",
    "kmeans.fit(x)\n",
    "identified_clusters = kmeans.fit_predict(x)\n",
    "centroids = kmeans.cluster_centers_\n",
    "labels = kmeans.labels_\n",
    "clusters_set = count_groups(30, labels, centroids)\n",
    "\n",
    "\n",
    "    \n",
    "# Write cluster info to excel sheet\n",
    "\n",
    "# create workbook\n",
    "wb = Workbook()\n",
    "\n",
    "# create sheet\n",
    "sheet1 = wb.add_sheet('Dataset_42')\n",
    "\n",
    "\n",
    "# Make the header the list of botnet/benign types\n",
    "header = set().union(*(d.keys() for d in clusters_set))\n",
    "header = list(header)\n",
    "# Convert the dictionary values to a list of lists\n",
    "rows = list()\n",
    "i = 1\n",
    "for cluster in clusters_set:\n",
    "    row = list()\n",
    "    row.append(i)\n",
    "    for item in header:\n",
    "        try:\n",
    "            row.append(cluster[item])\n",
    "        except:\n",
    "            row.append(0)\n",
    "    rows.append(row)\n",
    "    i+=1\n",
    "    \n",
    "\n",
    "header.insert(0, 'Cluster #')\n",
    "\n",
    "for col in range(0, len(header)):\n",
    "#     print(header[col])\n",
    "\n",
    "    # print column header\n",
    "    sheet1.write(0, col, header[col])\n",
    "    # print each row in column\n",
    "    for row in range(0, len(rows)):\n",
    "        sheet1.write(row+1, col, rows[row][col])\n",
    "\n",
    "print('success!')\n",
    "\n",
    "    \n",
    "wb.save('working_data/clusters_chart.xls')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(botnets))\n",
    "print(len(benign))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Useful Resources:\n",
    "\n",
    "https://www.geeksforgeeks.org/convert-a-categorical-variable-into-dummy-variables/?ref=rp"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
